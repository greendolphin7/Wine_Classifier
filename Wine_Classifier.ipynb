{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\clubc\\\\Desktop\\\\python_basic'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "목표 : 레드와인과 화이트와인 구분하기"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "데이터 : UCI Machine Learning Repository (https://archive.ics.uci.edu)\n",
    "- 레드와인 1599개, 화이트와인 4898개를 합친 데이터 = 6,497개 행, 13개 컬럼 데이터\n",
    "- 12가지 features : 주석산 농도, 아세트산 농도, 구연산 농도, 잔류 당분 농도, 염화나트륨 농도, 유리 아황산 농도, 총 아황산 농도, 밀도, PH, 황산칼륨 농도, 알코올 도수, 와인의 맛(0~10등급)\n",
    "- class : 레드와인(1), 화이트와인(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정 (환경을 같게 만들어주어, 딥러닝 실행 시 같은 값이 나올 수 있게 해줌)\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.99460</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.097</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.99590</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.99430</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.176</td>\n",
       "      <td>52.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.170</td>\n",
       "      <td>51.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.93</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.092</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.341</td>\n",
       "      <td>17.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.077</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.082</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.084</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.085</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.080</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.080</td>\n",
       "      <td>14.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.082</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.046</td>\n",
       "      <td>42.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.99324</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.33</td>\n",
       "      <td>10.10</td>\n",
       "      <td>0.032</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99626</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.021</td>\n",
       "      <td>29.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99188</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.015</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98970</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.55</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.032</td>\n",
       "      <td>50.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.99622</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.030</td>\n",
       "      <td>33.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99044</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.52</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6473</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.048</td>\n",
       "      <td>16.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99282</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.035</td>\n",
       "      <td>18.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99245</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.038</td>\n",
       "      <td>34.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99132</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.032</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.99286</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.035</td>\n",
       "      <td>6.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.99234</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6480</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6481</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.037</td>\n",
       "      <td>45.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.99184</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.035</td>\n",
       "      <td>60.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.98964</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.38</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>68.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99492</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.40</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.046</td>\n",
       "      <td>68.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.99494</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.550000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.28</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.028</td>\n",
       "      <td>45.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99168</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1.08</td>\n",
       "      <td>12.150000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.023</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.98928</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.052</td>\n",
       "      <td>38.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.99330</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>4.9</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.036</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.98938</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.038</td>\n",
       "      <td>38.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99074</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.032</td>\n",
       "      <td>29.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99298</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2      3      4     5      6        7     8     9   \\\n",
       "0      7.4  0.700  0.00   1.90  0.076  11.0   34.0  0.99780  3.51  0.56   \n",
       "1      7.8  0.880  0.00   2.60  0.098  25.0   67.0  0.99680  3.20  0.68   \n",
       "2      7.8  0.760  0.04   2.30  0.092  15.0   54.0  0.99700  3.26  0.65   \n",
       "3     11.2  0.280  0.56   1.90  0.075  17.0   60.0  0.99800  3.16  0.58   \n",
       "4      7.4  0.700  0.00   1.90  0.076  11.0   34.0  0.99780  3.51  0.56   \n",
       "5      7.4  0.660  0.00   1.80  0.075  13.0   40.0  0.99780  3.51  0.56   \n",
       "6      7.9  0.600  0.06   1.60  0.069  15.0   59.0  0.99640  3.30  0.46   \n",
       "7      7.3  0.650  0.00   1.20  0.065  15.0   21.0  0.99460  3.39  0.47   \n",
       "8      7.8  0.580  0.02   2.00  0.073   9.0   18.0  0.99680  3.36  0.57   \n",
       "9      7.5  0.500  0.36   6.10  0.071  17.0  102.0  0.99780  3.35  0.80   \n",
       "10     6.7  0.580  0.08   1.80  0.097  15.0   65.0  0.99590  3.28  0.54   \n",
       "11     7.5  0.500  0.36   6.10  0.071  17.0  102.0  0.99780  3.35  0.80   \n",
       "12     5.6  0.615  0.00   1.60  0.089  16.0   59.0  0.99430  3.58  0.52   \n",
       "13     7.8  0.610  0.29   1.60  0.114   9.0   29.0  0.99740  3.26  1.56   \n",
       "14     8.9  0.620  0.18   3.80  0.176  52.0  145.0  0.99860  3.16  0.88   \n",
       "15     8.9  0.620  0.19   3.90  0.170  51.0  148.0  0.99860  3.17  0.93   \n",
       "16     8.5  0.280  0.56   1.80  0.092  35.0  103.0  0.99690  3.30  0.75   \n",
       "17     8.1  0.560  0.28   1.70  0.368  16.0   56.0  0.99680  3.11  1.28   \n",
       "18     7.4  0.590  0.08   4.40  0.086   6.0   29.0  0.99740  3.38  0.50   \n",
       "19     7.9  0.320  0.51   1.80  0.341  17.0   56.0  0.99690  3.04  1.08   \n",
       "20     8.9  0.220  0.48   1.80  0.077  29.0   60.0  0.99680  3.39  0.53   \n",
       "21     7.6  0.390  0.31   2.30  0.082  23.0   71.0  0.99820  3.52  0.65   \n",
       "22     7.9  0.430  0.21   1.60  0.106  10.0   37.0  0.99660  3.17  0.91   \n",
       "23     8.5  0.490  0.11   2.30  0.084   9.0   67.0  0.99680  3.17  0.53   \n",
       "24     6.9  0.400  0.14   2.40  0.085  21.0   40.0  0.99680  3.43  0.63   \n",
       "25     6.3  0.390  0.16   1.40  0.080  11.0   23.0  0.99550  3.34  0.56   \n",
       "26     7.6  0.410  0.24   1.80  0.080   4.0   11.0  0.99620  3.28  0.59   \n",
       "27     7.9  0.430  0.21   1.60  0.106  10.0   37.0  0.99660  3.17  0.91   \n",
       "28     7.1  0.710  0.00   1.90  0.080  14.0   35.0  0.99720  3.47  0.55   \n",
       "29     7.8  0.645  0.00   2.00  0.082   8.0   16.0  0.99640  3.38  0.59   \n",
       "...    ...    ...   ...    ...    ...   ...    ...      ...   ...   ...   \n",
       "6467   5.8  0.230  0.31   4.50  0.046  42.0  124.0  0.99324  3.31  0.64   \n",
       "6468   6.6  0.240  0.33  10.10  0.032   8.0   81.0  0.99626  3.19  0.51   \n",
       "6469   6.1  0.320  0.28   6.60  0.021  29.0  132.0  0.99188  3.15  0.36   \n",
       "6470   5.0  0.200  0.40   1.90  0.015  20.0   98.0  0.98970  3.37  0.55   \n",
       "6471   6.0  0.420  0.41  12.40  0.032  50.0  179.0  0.99622  3.14  0.60   \n",
       "6472   5.7  0.210  0.32   1.60  0.030  33.0  122.0  0.99044  3.33  0.52   \n",
       "6473   5.6  0.200  0.36   2.50  0.048  16.0  125.0  0.99282  3.49  0.49   \n",
       "6474   7.4  0.220  0.26   1.20  0.035  18.0   97.0  0.99245  3.12  0.41   \n",
       "6475   6.2  0.380  0.42   2.50  0.038  34.0  117.0  0.99132  3.36  0.59   \n",
       "6476   5.9  0.540  0.00   0.80  0.032  12.0   82.0  0.99286  3.25  0.36   \n",
       "6477   6.2  0.530  0.02   0.90  0.035   6.0   81.0  0.99234  3.24  0.35   \n",
       "6478   6.6  0.340  0.40   8.10  0.046  68.0  170.0  0.99494  3.15  0.50   \n",
       "6479   6.6  0.340  0.40   8.10  0.046  68.0  170.0  0.99494  3.15  0.50   \n",
       "6480   5.0  0.235  0.27  11.75  0.030  34.0  118.0  0.99540  3.07  0.50   \n",
       "6481   5.5  0.320  0.13   1.30  0.037  45.0  156.0  0.99184  3.26  0.38   \n",
       "6482   4.9  0.470  0.17   1.90  0.035  60.0  148.0  0.98964  3.27  0.35   \n",
       "6483   6.5  0.330  0.38   8.30  0.048  68.0  174.0  0.99492  3.14  0.50   \n",
       "6484   6.6  0.340  0.40   8.10  0.046  68.0  170.0  0.99494  3.15  0.50   \n",
       "6485   6.2  0.210  0.28   5.70  0.028  45.0  121.0  0.99168  3.21  1.08   \n",
       "6486   6.2  0.410  0.22   1.90  0.023   5.0   56.0  0.98928  3.04  0.79   \n",
       "6487   6.8  0.220  0.36   1.20  0.052  38.0  127.0  0.99330  3.04  0.54   \n",
       "6488   4.9  0.235  0.27  11.75  0.030  34.0  118.0  0.99540  3.07  0.50   \n",
       "6489   6.1  0.340  0.29   2.20  0.036  25.0  100.0  0.98938  3.06  0.44   \n",
       "6490   5.7  0.210  0.32   0.90  0.038  38.0  121.0  0.99074  3.24  0.46   \n",
       "6491   6.5  0.230  0.38   1.30  0.032  29.0  112.0  0.99298  3.29  0.54   \n",
       "6492   6.2  0.210  0.29   1.60  0.039  24.0   92.0  0.99114  3.27  0.50   \n",
       "6493   6.6  0.320  0.36   8.00  0.047  57.0  168.0  0.99490  3.15  0.46   \n",
       "6494   6.5  0.240  0.19   1.20  0.041  30.0  111.0  0.99254  2.99  0.46   \n",
       "6495   5.5  0.290  0.30   1.10  0.022  20.0  110.0  0.98869  3.34  0.38   \n",
       "6496   6.0  0.210  0.38   0.80  0.020  22.0   98.0  0.98941  3.26  0.32   \n",
       "\n",
       "             10  11  12  \n",
       "0      9.400000   5   1  \n",
       "1      9.800000   5   1  \n",
       "2      9.800000   5   1  \n",
       "3      9.800000   6   1  \n",
       "4      9.400000   5   1  \n",
       "5      9.400000   5   1  \n",
       "6      9.400000   5   1  \n",
       "7     10.000000   7   1  \n",
       "8      9.500000   7   1  \n",
       "9     10.500000   5   1  \n",
       "10     9.200000   5   1  \n",
       "11    10.500000   5   1  \n",
       "12     9.900000   5   1  \n",
       "13     9.100000   5   1  \n",
       "14     9.200000   5   1  \n",
       "15     9.200000   5   1  \n",
       "16    10.500000   7   1  \n",
       "17     9.300000   5   1  \n",
       "18     9.000000   4   1  \n",
       "19     9.200000   6   1  \n",
       "20     9.400000   6   1  \n",
       "21     9.700000   5   1  \n",
       "22     9.500000   5   1  \n",
       "23     9.400000   5   1  \n",
       "24     9.700000   6   1  \n",
       "25     9.300000   5   1  \n",
       "26     9.500000   5   1  \n",
       "27     9.500000   5   1  \n",
       "28     9.400000   5   1  \n",
       "29     9.800000   6   1  \n",
       "...         ...  ..  ..  \n",
       "6467  10.800000   6   0  \n",
       "6468   9.800000   6   0  \n",
       "6469  11.450000   7   0  \n",
       "6470  12.050000   6   0  \n",
       "6471   9.700000   5   0  \n",
       "6472  11.900000   6   0  \n",
       "6473  10.000000   6   0  \n",
       "6474   9.700000   6   0  \n",
       "6475  11.600000   7   0  \n",
       "6476   8.800000   5   0  \n",
       "6477   9.500000   4   0  \n",
       "6478   9.533333   6   0  \n",
       "6479   9.533333   6   0  \n",
       "6480   9.400000   6   0  \n",
       "6481  10.700000   5   0  \n",
       "6482  11.500000   6   0  \n",
       "6483   9.600000   5   0  \n",
       "6484   9.550000   6   0  \n",
       "6485  12.150000   7   0  \n",
       "6486  13.000000   7   0  \n",
       "6487   9.200000   5   0  \n",
       "6488   9.400000   6   0  \n",
       "6489  11.800000   6   0  \n",
       "6490  10.600000   6   0  \n",
       "6491   9.700000   5   0  \n",
       "6492  11.200000   6   0  \n",
       "6493   9.600000   5   0  \n",
       "6494   9.400000   6   0  \n",
       "6495  12.800000   7   0  \n",
       "6496  11.800000   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 입력\n",
    "df_pre = pd.read_csv('./data_wine/wine.csv', header=None)\n",
    "df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.053</td>\n",
       "      <td>20.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.99373</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.047</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.99164</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.54</td>\n",
       "      <td>11.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.049</td>\n",
       "      <td>56.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.074</td>\n",
       "      <td>25.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99370</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.034</td>\n",
       "      <td>29.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.19</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.055</td>\n",
       "      <td>27.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.99530</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.046</td>\n",
       "      <td>31.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99226</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.048</td>\n",
       "      <td>52.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.99784</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.076</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.99551</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.20</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0.046</td>\n",
       "      <td>60.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99526</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.80</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.085</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.99683</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.048</td>\n",
       "      <td>36.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99670</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.037</td>\n",
       "      <td>26.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99430</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>11.20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.077</td>\n",
       "      <td>15.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99746</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.044</td>\n",
       "      <td>35.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.99326</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.028</td>\n",
       "      <td>23.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.29</td>\n",
       "      <td>15.40</td>\n",
       "      <td>0.073</td>\n",
       "      <td>56.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.99840</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.41</td>\n",
       "      <td>8.70</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.072</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99600</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>5.1</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.034</td>\n",
       "      <td>26.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.99449</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>8.4</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.194</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99536</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.78</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.160</td>\n",
       "      <td>34.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.98840</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>13.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.057</td>\n",
       "      <td>34.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.99554</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>10.4</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.73</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.074</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.24</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.044</td>\n",
       "      <td>60.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.99890</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>41.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3816</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0.051</td>\n",
       "      <td>18.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>11.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.34</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.044</td>\n",
       "      <td>66.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.046</td>\n",
       "      <td>24.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.99232</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.058</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9.10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.054</td>\n",
       "      <td>23.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.080</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.044</td>\n",
       "      <td>12.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99230</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.26</td>\n",
       "      <td>13.10</td>\n",
       "      <td>0.051</td>\n",
       "      <td>44.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.24</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.048</td>\n",
       "      <td>24.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.80</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.37</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.025</td>\n",
       "      <td>31.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99082</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.038</td>\n",
       "      <td>37.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99026</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12.60</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.066</td>\n",
       "      <td>38.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99450</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.30</td>\n",
       "      <td>9.15</td>\n",
       "      <td>0.051</td>\n",
       "      <td>25.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.99339</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.35</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.036</td>\n",
       "      <td>23.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.98949</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.77</td>\n",
       "      <td>13.40</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11.60</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.084</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.77</td>\n",
       "      <td>10.70</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.24</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.050</td>\n",
       "      <td>55.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>9.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.39</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.040</td>\n",
       "      <td>45.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.99250</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>12.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.99130</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.51</td>\n",
       "      <td>15.30</td>\n",
       "      <td>0.047</td>\n",
       "      <td>54.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.99360</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.80</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.073</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.045</td>\n",
       "      <td>25.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.99222</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>11.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.035</td>\n",
       "      <td>41.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.99520</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>10.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.054</td>\n",
       "      <td>47.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.99538</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.20</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.044</td>\n",
       "      <td>41.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.99862</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.05</td>\n",
       "      <td>0.045</td>\n",
       "      <td>37.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.99352</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.70</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.089</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99592</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>10.40</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.23</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.048</td>\n",
       "      <td>33.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.99612</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.90</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.31</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.045</td>\n",
       "      <td>39.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.059</td>\n",
       "      <td>29.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.99177</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.036</td>\n",
       "      <td>48.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99110</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.51</td>\n",
       "      <td>11.50</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.147</td>\n",
       "      <td>38.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.059</td>\n",
       "      <td>45.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.30</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.053</td>\n",
       "      <td>27.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2      3      4     5      6        7     8     9   \\\n",
       "5316   6.3  0.180  0.24   3.40  0.053  20.0  119.0  0.99373  3.11  0.52   \n",
       "5210   6.8  0.140  0.18   1.40  0.047  30.0   90.0  0.99164  3.27  0.54   \n",
       "3518   7.3  0.220  0.50  13.70  0.049  56.0  189.0  0.99940  3.24  0.66   \n",
       "1622   7.6  0.670  0.14   1.50  0.074  25.0  168.0  0.99370  3.05  0.51   \n",
       "2443   7.3  0.210  0.29   1.60  0.034  29.0  118.0  0.99170  3.30  0.50   \n",
       "3521   7.0  0.120  0.19   4.90  0.055  27.0  127.0  0.99530  3.29  0.41   \n",
       "5211   6.8  0.160  0.18   1.80  0.046  31.0  114.0  0.99226  3.27  0.55   \n",
       "4936   6.9  0.380  0.29  13.65  0.048  52.0  189.0  0.99784  3.00  0.60   \n",
       "1161   8.8  0.450  0.43   1.40  0.076  12.0   21.0  0.99551  3.21  0.75   \n",
       "5993   6.3  0.200  0.26  12.70  0.046  60.0  143.0  0.99526  3.26  0.35   \n",
       "1035  10.1  0.370  0.34   2.40  0.085   5.0   17.0  0.99683  3.17  0.65   \n",
       "3788   7.1  0.180  0.32  12.20  0.048  36.0  125.0  0.99670  2.92  0.54   \n",
       "3130   8.1  0.300  0.49   8.10  0.037  26.0  174.0  0.99430  3.10  0.30   \n",
       "864    7.2  0.620  0.06   2.70  0.077  15.0   85.0  0.99746  3.51  0.54   \n",
       "4797   6.4  0.220  0.38   9.10  0.044  35.0  127.0  0.99326  2.97  0.30   \n",
       "2572   6.5  0.080  0.33   1.90  0.028  23.0   93.0  0.99100  3.34  0.70   \n",
       "3397   6.8  0.230  0.29  15.40  0.073  56.0  173.0  0.99840  3.06  0.41   \n",
       "311    7.9  0.530  0.24   2.00  0.072  15.0  105.0  0.99600  3.27  0.54   \n",
       "6404   5.1  0.260  0.34   6.40  0.034  26.0   99.0  0.99449  3.23  0.41   \n",
       "882    8.4  0.310  0.29   3.10  0.194  14.0   26.0  0.99536  3.22  0.78   \n",
       "5334   6.1  0.220  0.46   1.80  0.160  34.0   74.0  0.98840  3.19  0.33   \n",
       "5045   7.3  0.340  0.30   9.40  0.057  34.0  178.0  0.99554  3.15  0.44   \n",
       "502   10.4  0.440  0.73   6.55  0.074  38.0   76.0  0.99900  3.17  0.85   \n",
       "1817   5.7  0.280  0.24  17.50  0.044  60.0  167.0  0.99890  3.31  0.44   \n",
       "4434   6.3  0.250  0.22   3.30  0.048  41.0  161.0  0.99256  3.16  0.50   \n",
       "3816   8.1  0.250  0.38   3.80  0.051  18.0  129.0  0.99280  3.21  0.38   \n",
       "4315   7.8  0.250  0.34  13.70  0.044  66.0  184.0  0.99976  3.22  0.75   \n",
       "4442   5.9  0.220  0.38   1.30  0.046  24.0   90.0  0.99232  3.20  0.47   \n",
       "170    7.9  0.885  0.03   1.80  0.058   4.0    8.0  0.99720  3.36  0.33   \n",
       "1748   6.9  0.250  0.30   4.10  0.054  23.0  116.0  0.99400  2.99  0.38   \n",
       "...    ...    ...   ...    ...    ...   ...    ...      ...   ...   ...   \n",
       "99     8.1  0.545  0.18   1.90  0.080  13.0   35.0  0.99720  3.30  0.59   \n",
       "2496   7.0  0.290  0.26   1.60  0.044  12.0   87.0  0.99230  3.08  0.46   \n",
       "1871   5.8  0.250  0.26  13.10  0.051  44.0  148.0  0.99720  3.29  0.38   \n",
       "2046   6.5  0.410  0.24  14.00  0.048  24.0  113.0  0.99820  3.44  0.53   \n",
       "4851   7.1  0.260  0.37   5.50  0.025  31.0  105.0  0.99082  3.06  0.33   \n",
       "5072   6.5  0.300  0.27   4.00  0.038  37.0   97.0  0.99026  3.20  0.60   \n",
       "2163   6.8  0.510  0.30   4.20  0.066  38.0  165.0  0.99450  3.20  0.42   \n",
       "6036   6.5  0.290  0.30   9.15  0.051  25.0  166.0  0.99339  3.24  0.56   \n",
       "6216   5.2  0.500  0.18   2.00  0.036  23.0  129.0  0.98949  3.36  0.77   \n",
       "2893   6.9  0.410  0.22   4.20  0.031  10.0  102.0  0.99300  3.00  0.86   \n",
       "537    8.1  0.825  0.24   2.10  0.084   5.0   13.0  0.99720  3.37  0.77   \n",
       "1701   6.0  0.210  0.24  12.10  0.050  55.0  164.0  0.99700  3.34  0.39   \n",
       "2897   7.3  0.340  0.39   5.20  0.040  45.0  163.0  0.99250  3.30  0.47   \n",
       "2222   7.2  0.240  0.34   1.10  0.045   3.0   64.0  0.99130  3.23  0.51   \n",
       "2135   7.9  0.345  0.51  15.30  0.047  54.0  171.0  0.99870  3.09  0.51   \n",
       "2599   8.0  0.190  0.36   1.80  0.050  16.0   84.0  0.99360  3.15  0.45   \n",
       "705    8.4  1.035  0.15   6.00  0.073  11.0   54.0  0.99900  3.37  0.49   \n",
       "6458   6.0  0.430  0.34   7.60  0.045  25.0  118.0  0.99222  3.03  0.37   \n",
       "3468   8.2  0.180  0.28   8.50  0.035  41.0  140.0  0.99520  3.04  0.37   \n",
       "5924   6.4  0.240  0.26   8.20  0.054  47.0  182.0  0.99538  3.12  0.50   \n",
       "5874   5.7  0.220  0.20  16.00  0.044  41.0  113.0  0.99862  3.22  0.46   \n",
       "4373   7.0  0.360  0.32  10.05  0.045  37.0  131.0  0.99352  3.09  0.33   \n",
       "1033   7.5  0.570  0.08   2.60  0.089  14.0   27.0  0.99592  3.30  0.59   \n",
       "5827   6.2  0.290  0.23  12.40  0.048  33.0  201.0  0.99612  3.11  0.56   \n",
       "4859   7.4  0.190  0.31  14.50  0.045  39.0  193.0  0.99860  3.10  0.50   \n",
       "4931   6.5  0.220  0.28   3.70  0.059  29.0  151.0  0.99177  3.23  0.41   \n",
       "3264   6.5  0.130  0.37   1.00  0.036  48.0  114.0  0.99110  3.41  0.51   \n",
       "1653   6.8  0.200  0.59   0.90  0.147  38.0  132.0  0.99300  3.05  0.38   \n",
       "2607   6.6  0.220  0.37   1.20  0.059  45.0  199.0  0.99300  3.37  0.55   \n",
       "2732   8.7  0.220  0.42   2.30  0.053  27.0  114.0  0.99400  2.99  0.43   \n",
       "\n",
       "         10  11  12  \n",
       "5316   9.20   6   0  \n",
       "5210  11.20   6   0  \n",
       "3518   9.00   6   0  \n",
       "1622   9.30   5   0  \n",
       "2443  11.00   8   0  \n",
       "3521   9.40   5   0  \n",
       "5211  10.80   6   0  \n",
       "4936   9.50   6   0  \n",
       "1161  10.20   6   1  \n",
       "5993  10.80   6   0  \n",
       "1035  10.60   7   1  \n",
       "3788   9.40   6   0  \n",
       "3130  11.20   7   0  \n",
       "864    9.50   5   1  \n",
       "4797  11.00   7   0  \n",
       "2572  12.00   7   0  \n",
       "3397   8.70   6   0  \n",
       "311    9.40   6   1  \n",
       "6404   9.20   6   0  \n",
       "882   12.00   6   1  \n",
       "5334  13.40   6   0  \n",
       "5045  10.40   6   0  \n",
       "502   12.00   7   1  \n",
       "1817   9.40   5   0  \n",
       "4434  10.50   6   0  \n",
       "3816  11.50   6   0  \n",
       "4315   8.90   5   0  \n",
       "4442  10.00   6   0  \n",
       "170    9.10   4   1  \n",
       "1748   9.40   6   0  \n",
       "...     ...  ..  ..  \n",
       "99     9.00   6   1  \n",
       "2496  10.50   6   0  \n",
       "1871   9.30   5   0  \n",
       "2046   9.80   6   0  \n",
       "4851  12.60   8   0  \n",
       "5072  12.60   8   0  \n",
       "2163   9.10   5   0  \n",
       "6036  11.35   6   0  \n",
       "6216  13.40   7   0  \n",
       "2893  11.60   4   0  \n",
       "537   10.70   6   1  \n",
       "1701   9.40   5   0  \n",
       "2897  12.40   6   0  \n",
       "2222  11.40   5   0  \n",
       "2135   9.10   5   0  \n",
       "2599   9.80   7   0  \n",
       "705    9.90   5   1  \n",
       "6458  11.00   6   0  \n",
       "3468  10.10   7   0  \n",
       "5924   9.50   5   0  \n",
       "5874   8.90   6   0  \n",
       "4373  11.70   8   0  \n",
       "1033  10.40   6   1  \n",
       "5827   9.90   6   0  \n",
       "4859   9.20   6   0  \n",
       "4931  12.10   7   0  \n",
       "3264  11.50   8   0  \n",
       "1653   9.10   6   0  \n",
       "2607  10.30   7   0  \n",
       "2732  10.00   5   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 샘플링\n",
    "df = df_pre.sample(frac=1)  # 랜덤 샘플을 가져오는데, 원본 데이터의 100%를 가져오라는 뜻(frac=0.5로 지정하면 50%만 랜덤으로 가져옴)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3 ,  0.18,  0.24, ...,  9.2 ,  6.  ,  0.  ],\n",
       "       [ 6.8 ,  0.14,  0.18, ..., 11.2 ,  6.  ,  0.  ],\n",
       "       [ 7.3 ,  0.22,  0.5 , ...,  9.  ,  6.  ,  0.  ],\n",
       "       ...,\n",
       "       [ 6.8 ,  0.2 ,  0.59, ...,  9.1 ,  6.  ,  0.  ],\n",
       "       [ 6.6 ,  0.22,  0.37, ..., 10.3 ,  7.  ,  0.  ],\n",
       "       [ 8.7 ,  0.22,  0.42, ..., 10.  ,  5.  ,  0.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3 ,  0.18,  0.24, ...,  0.52,  9.2 ,  6.  ],\n",
       "       [ 6.8 ,  0.14,  0.18, ...,  0.54, 11.2 ,  6.  ],\n",
       "       [ 7.3 ,  0.22,  0.5 , ...,  0.66,  9.  ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.8 ,  0.2 ,  0.59, ...,  0.38,  9.1 ,  6.  ],\n",
       "       [ 6.6 ,  0.22,  0.37, ...,  0.55, 10.3 ,  7.  ],\n",
       "       [ 8.7 ,  0.22,  0.42, ...,  0.43, 10.  ,  5.  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(32,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "           optimizer='adam',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 체크포인트 만들어서 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "# 모델 저장 조건 설정\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼리스타핑 만들어서 과적합 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 그래프 없이 오차 및 정확도 측정[checkpointer, early_stopping_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.59636, saving model to ./model\\01-7.5964.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.59636 to 0.44418, saving model to ./model\\02-0.4442.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44418 to 0.24183, saving model to ./model\\03-0.2418.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.24183 to 0.20928, saving model to ./model\\04-0.2093.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20928 to 0.20296, saving model to ./model\\05-0.2030.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20296 to 0.19914, saving model to ./model\\06-0.1991.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19914 to 0.19513, saving model to ./model\\07-0.1951.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19513\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19513 to 0.18796, saving model to ./model\\09-0.1880.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18796 to 0.18640, saving model to ./model\\10-0.1864.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18640 to 0.17984, saving model to ./model\\11-0.1798.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.17984 to 0.17638, saving model to ./model\\12-0.1764.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17638 to 0.17188, saving model to ./model\\13-0.1719.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17188 to 0.16843, saving model to ./model\\14-0.1684.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16843 to 0.16512, saving model to ./model\\15-0.1651.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16512 to 0.16182, saving model to ./model\\16-0.1618.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16182 to 0.15425, saving model to ./model\\17-0.1542.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.15425 to 0.14829, saving model to ./model\\18-0.1483.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.14829 to 0.14472, saving model to ./model\\19-0.1447.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.14472 to 0.13892, saving model to ./model\\20-0.1389.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.13892 to 0.13824, saving model to ./model\\21-0.1382.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.13824 to 0.13018, saving model to ./model\\22-0.1302.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.13018 to 0.12382, saving model to ./model\\23-0.1238.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.12382 to 0.11917, saving model to ./model\\24-0.1192.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11917 to 0.11696, saving model to ./model\\25-0.1170.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11696\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11696 to 0.11073, saving model to ./model\\27-0.1107.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11073\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11073\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11073 to 0.10423, saving model to ./model\\30-0.1042.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10423 to 0.10259, saving model to ./model\\31-0.1026.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10259\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.10259 to 0.09726, saving model to ./model\\33-0.0973.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09726 to 0.09370, saving model to ./model\\34-0.0937.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.09370 to 0.09021, saving model to ./model\\35-0.0902.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09021 to 0.08735, saving model to ./model\\36-0.0873.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08735\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08735 to 0.08676, saving model to ./model\\38-0.0868.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.08676 to 0.08218, saving model to ./model\\39-0.0822.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08218 to 0.08051, saving model to ./model\\40-0.0805.hdf5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08051\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.08051 to 0.07742, saving model to ./model\\42-0.0774.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.07742 to 0.07693, saving model to ./model\\43-0.0769.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07693\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07693\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.07693 to 0.07311, saving model to ./model\\46-0.0731.hdf5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07311\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.07311 to 0.07125, saving model to ./model\\48-0.0712.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.07125 to 0.07058, saving model to ./model\\49-0.0706.hdf5\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07058\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.07058 to 0.06820, saving model to ./model\\51-0.0682.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.06820\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.06820\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06820\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.06820 to 0.06647, saving model to ./model\\55-0.0665.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.06647 to 0.06556, saving model to ./model\\56-0.0656.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.06556\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06556\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06556\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.06556 to 0.06534, saving model to ./model\\60-0.0653.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.06534 to 0.06362, saving model to ./model\\61-0.0636.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.06362 to 0.06209, saving model to ./model\\62-0.0621.hdf5\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06209\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.06209 to 0.06141, saving model to ./model\\64-0.0614.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.06141\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.06141 to 0.05958, saving model to ./model\\66-0.0596.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05958\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.05958 to 0.05937, saving model to ./model\\68-0.0594.hdf5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05937\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05937\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05937\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.05937\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.05937 to 0.05890, saving model to ./model\\73-0.0589.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.05890 to 0.05827, saving model to ./model\\74-0.0583.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05827\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05827\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05827\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05827\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05827\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.05827 to 0.05739, saving model to ./model\\80-0.0574.hdf5\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05739\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05739\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.05739 to 0.05709, saving model to ./model\\83-0.0571.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.05709 to 0.05682, saving model to ./model\\84-0.0568.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05682\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05682\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05682\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.05682 to 0.05593, saving model to ./model\\88-0.0559.hdf5\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05593\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.05593 to 0.05454, saving model to ./model\\98-0.0545.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.05454 to 0.05435, saving model to ./model\\99-0.0544.hdf5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05435\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05435 to 0.05386, saving model to ./model\\101-0.0539.hdf5\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05386\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00111: val_loss did not improve from 0.05386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208b779beb8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 실행\n",
    "model.fit(X, Y, validation_split=0.2, epochs=1000, batch_size=200, verbose=0, callbacks=[checkpointer, early_stopping_callback])\n",
    "# 앞서 저장한 모델보다 나은 결과값(테스트 오차값이 감소)이 나올 때만 모델을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9845\n",
      "\n",
      " Accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 그래프로 테스트셋 오차, 학습셋 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5197 samples, validate on 1300 samples\n",
      "Epoch 1/1000\n",
      "5197/5197 [==============================] - 0s 35us/step - loss: 0.5127 - accuracy: 0.8482 - val_loss: 0.3040 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30396, saving model to ./model/01-0.3040.hdf5\n",
      "Epoch 2/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.2780 - accuracy: 0.8913 - val_loss: 0.2642 - val_accuracy: 0.9023\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30396 to 0.26418, saving model to ./model/02-0.2642.hdf5\n",
      "Epoch 3/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.2259 - accuracy: 0.9221 - val_loss: 0.2187 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26418 to 0.21872, saving model to ./model/03-0.2187.hdf5\n",
      "Epoch 4/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.2034 - accuracy: 0.9319 - val_loss: 0.2086 - val_accuracy: 0.9308\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21872 to 0.20861, saving model to ./model/04-0.2086.hdf5\n",
      "Epoch 5/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1977 - accuracy: 0.9317 - val_loss: 0.2054 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20861 to 0.20537, saving model to ./model/05-0.2054.hdf5\n",
      "Epoch 6/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1918 - accuracy: 0.9334 - val_loss: 0.2022 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20537 to 0.20218, saving model to ./model/06-0.2022.hdf5\n",
      "Epoch 7/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1880 - accuracy: 0.9340 - val_loss: 0.1967 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20218 to 0.19674, saving model to ./model/07-0.1967.hdf5\n",
      "Epoch 8/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1849 - accuracy: 0.9353 - val_loss: 0.1969 - val_accuracy: 0.9292\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19674\n",
      "Epoch 9/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1818 - accuracy: 0.9382 - val_loss: 0.1885 - val_accuracy: 0.9346\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19674 to 0.18851, saving model to ./model/09-0.1885.hdf5\n",
      "Epoch 10/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1783 - accuracy: 0.9386 - val_loss: 0.1846 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18851 to 0.18457, saving model to ./model/10-0.1846.hdf5\n",
      "Epoch 11/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1741 - accuracy: 0.9402 - val_loss: 0.1822 - val_accuracy: 0.9377\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18457 to 0.18222, saving model to ./model/11-0.1822.hdf5\n",
      "Epoch 12/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1726 - accuracy: 0.9392 - val_loss: 0.1763 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18222 to 0.17634, saving model to ./model/12-0.1763.hdf5\n",
      "Epoch 13/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1683 - accuracy: 0.9400 - val_loss: 0.1735 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17634 to 0.17351, saving model to ./model/13-0.1735.hdf5\n",
      "Epoch 14/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1652 - accuracy: 0.9427 - val_loss: 0.1683 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17351 to 0.16831, saving model to ./model/14-0.1683.hdf5\n",
      "Epoch 15/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1609 - accuracy: 0.9432 - val_loss: 0.1640 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.16831 to 0.16402, saving model to ./model/15-0.1640.hdf5\n",
      "Epoch 16/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1556 - accuracy: 0.9444 - val_loss: 0.1565 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16402 to 0.15654, saving model to ./model/16-0.1565.hdf5\n",
      "Epoch 17/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1506 - accuracy: 0.9465 - val_loss: 0.1543 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.15654 to 0.15429, saving model to ./model/17-0.1543.hdf5\n",
      "Epoch 18/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1526 - accuracy: 0.9440 - val_loss: 0.1488 - val_accuracy: 0.9477\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.15429 to 0.14876, saving model to ./model/18-0.1488.hdf5\n",
      "Epoch 19/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1423 - accuracy: 0.9469 - val_loss: 0.1528 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14876\n",
      "Epoch 20/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.1405 - accuracy: 0.9496 - val_loss: 0.1404 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.14876 to 0.14038, saving model to ./model/20-0.1404.hdf5\n",
      "Epoch 21/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1334 - accuracy: 0.9502 - val_loss: 0.1364 - val_accuracy: 0.9477\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.14038 to 0.13639, saving model to ./model/21-0.1364.hdf5\n",
      "Epoch 22/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.1286 - accuracy: 0.9511 - val_loss: 0.1266 - val_accuracy: 0.9577\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.13639 to 0.12658, saving model to ./model/22-0.1266.hdf5\n",
      "Epoch 23/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1203 - accuracy: 0.9565 - val_loss: 0.1215 - val_accuracy: 0.9585\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.12658 to 0.12154, saving model to ./model/23-0.1215.hdf5\n",
      "Epoch 24/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1184 - accuracy: 0.9579 - val_loss: 0.1189 - val_accuracy: 0.9592\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.12154 to 0.11887, saving model to ./model/24-0.1189.hdf5\n",
      "Epoch 25/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1104 - accuracy: 0.9607 - val_loss: 0.1199 - val_accuracy: 0.9677\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11887\n",
      "Epoch 26/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1108 - accuracy: 0.9615 - val_loss: 0.1123 - val_accuracy: 0.9654\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.11887 to 0.11228, saving model to ./model/26-0.1123.hdf5\n",
      "Epoch 27/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1037 - accuracy: 0.9627 - val_loss: 0.1108 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11228 to 0.11077, saving model to ./model/27-0.1108.hdf5\n",
      "Epoch 28/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.1020 - accuracy: 0.9646 - val_loss: 0.1109 - val_accuracy: 0.9700\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11077\n",
      "Epoch 29/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0998 - accuracy: 0.9644 - val_loss: 0.1080 - val_accuracy: 0.9700\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11077 to 0.10800, saving model to ./model/29-0.1080.hdf5\n",
      "Epoch 30/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.1003 - accuracy: 0.9663 - val_loss: 0.1326 - val_accuracy: 0.9554\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10800\n",
      "Epoch 31/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0985 - accuracy: 0.9684 - val_loss: 0.1058 - val_accuracy: 0.9685\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10800 to 0.10581, saving model to ./model/31-0.1058.hdf5\n",
      "Epoch 32/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0909 - accuracy: 0.9708 - val_loss: 0.1017 - val_accuracy: 0.9708\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.10581 to 0.10174, saving model to ./model/32-0.1017.hdf5\n",
      "Epoch 33/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0926 - accuracy: 0.9684 - val_loss: 0.1187 - val_accuracy: 0.9731\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10174\n",
      "Epoch 34/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0858 - accuracy: 0.9729 - val_loss: 0.0990 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.10174 to 0.09905, saving model to ./model/34-0.0990.hdf5\n",
      "Epoch 35/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 0.1095 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09905\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197/5197 [==============================] - 0s 12us/step - loss: 0.0812 - accuracy: 0.9748 - val_loss: 0.0965 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.09905 to 0.09650, saving model to ./model/36-0.0965.hdf5\n",
      "Epoch 37/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0804 - accuracy: 0.9742 - val_loss: 0.1041 - val_accuracy: 0.9700\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.09650\n",
      "Epoch 38/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0786 - accuracy: 0.9734 - val_loss: 0.1147 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.09650\n",
      "Epoch 39/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0846 - accuracy: 0.9721 - val_loss: 0.0954 - val_accuracy: 0.9723\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.09650 to 0.09539, saving model to ./model/39-0.0954.hdf5\n",
      "Epoch 40/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0772 - accuracy: 0.9744 - val_loss: 0.0930 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.09539 to 0.09295, saving model to ./model/40-0.0930.hdf5\n",
      "Epoch 41/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.0943 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09295\n",
      "Epoch 42/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0714 - accuracy: 0.9771 - val_loss: 0.0910 - val_accuracy: 0.9762\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.09295 to 0.09098, saving model to ./model/42-0.0910.hdf5\n",
      "Epoch 43/1000\n",
      "5197/5197 [==============================] - 0s 12us/step - loss: 0.0723 - accuracy: 0.9761 - val_loss: 0.0987 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.09098\n",
      "Epoch 44/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0727 - accuracy: 0.9761 - val_loss: 0.0893 - val_accuracy: 0.9762\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.09098 to 0.08928, saving model to ./model/44-0.0893.hdf5\n",
      "Epoch 45/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0716 - accuracy: 0.9765 - val_loss: 0.0922 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08928\n",
      "Epoch 46/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0684 - accuracy: 0.9771 - val_loss: 0.0887 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08928 to 0.08872, saving model to ./model/46-0.0887.hdf5\n",
      "Epoch 47/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.0696 - accuracy: 0.9779 - val_loss: 0.0933 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08872\n",
      "Epoch 48/1000\n",
      "5197/5197 [==============================] - 0s 6us/step - loss: 0.0721 - accuracy: 0.9767 - val_loss: 0.0889 - val_accuracy: 0.9762\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08872\n",
      "Epoch 49/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0721 - accuracy: 0.9746 - val_loss: 0.0931 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08872\n",
      "Epoch 50/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0668 - accuracy: 0.9790 - val_loss: 0.0945 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08872\n",
      "Epoch 51/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0671 - accuracy: 0.9784 - val_loss: 0.0897 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08872\n",
      "Epoch 52/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0653 - accuracy: 0.9788 - val_loss: 0.0884 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08872 to 0.08836, saving model to ./model/52-0.0884.hdf5\n",
      "Epoch 53/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0630 - accuracy: 0.9804 - val_loss: 0.0872 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08836 to 0.08715, saving model to ./model/53-0.0872.hdf5\n",
      "Epoch 54/1000\n",
      "5197/5197 [==============================] - 0s 11us/step - loss: 0.0619 - accuracy: 0.9802 - val_loss: 0.0873 - val_accuracy: 0.9762\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08715\n",
      "Epoch 55/1000\n",
      "5197/5197 [==============================] - 0s 13us/step - loss: 0.0621 - accuracy: 0.9806 - val_loss: 0.0877 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.08715\n",
      "Epoch 56/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0921 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.08715\n",
      "Epoch 57/1000\n",
      "5197/5197 [==============================] - 0s 7us/step - loss: 0.0762 - accuracy: 0.9748 - val_loss: 0.0922 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08715\n",
      "Epoch 58/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.0869 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08715 to 0.08691, saving model to ./model/58-0.0869.hdf5\n",
      "Epoch 59/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.1046 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08691\n",
      "Epoch 60/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0600 - accuracy: 0.9821 - val_loss: 0.1022 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.08691\n",
      "Epoch 61/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0591 - accuracy: 0.9817 - val_loss: 0.0856 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.08691 to 0.08561, saving model to ./model/61-0.0856.hdf5\n",
      "Epoch 62/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0607 - accuracy: 0.9823 - val_loss: 0.0969 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.08561\n",
      "Epoch 63/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.1071 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.08561\n",
      "Epoch 64/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0883 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08561\n",
      "Epoch 65/1000\n",
      "5197/5197 [==============================] - 0s 11us/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.0856 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.08561 to 0.08560, saving model to ./model/65-0.0856.hdf5\n",
      "Epoch 66/1000\n",
      "5197/5197 [==============================] - 0s 12us/step - loss: 0.0581 - accuracy: 0.9823 - val_loss: 0.0853 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.08560 to 0.08530, saving model to ./model/66-0.0853.hdf5\n",
      "Epoch 67/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08530\n",
      "Epoch 68/1000\n",
      "5197/5197 [==============================] - 0s 9us/step - loss: 0.0606 - accuracy: 0.9825 - val_loss: 0.0883 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.08530\n",
      "Epoch 69/1000\n",
      "5197/5197 [==============================] - 0s 8us/step - loss: 0.0664 - accuracy: 0.9794 - val_loss: 0.0868 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08530\n",
      "Epoch 70/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0580 - accuracy: 0.9827 - val_loss: 0.0895 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08530\n",
      "Epoch 71/1000\n",
      "5197/5197 [==============================] - 0s 13us/step - loss: 0.0582 - accuracy: 0.9829 - val_loss: 0.0863 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.08530\n",
      "Epoch 72/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0573 - accuracy: 0.9831 - val_loss: 0.0879 - val_accuracy: 0.9808\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08530\n",
      "Epoch 73/1000\n",
      "5197/5197 [==============================] - 0s 11us/step - loss: 0.0569 - accuracy: 0.9835 - val_loss: 0.0888 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08530\n",
      "Epoch 74/1000\n",
      "5197/5197 [==============================] - 0s 12us/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.1044 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08530\n",
      "Epoch 75/1000\n",
      "5197/5197 [==============================] - 0s 12us/step - loss: 0.0662 - accuracy: 0.9796 - val_loss: 0.0938 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08530\n",
      "Epoch 76/1000\n",
      "5197/5197 [==============================] - 0s 10us/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 0.0854 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08530\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.2, epochs=1000, batch_size=200, verbose=1, callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋 오차를 저장\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# y_acc 에 학습셋 정확도를 저장\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "# y_val_accuracy에 테스트셋 정확도를 저장\n",
    "y_val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8600000143051147,\n",
       " 0.9023076891899109,\n",
       " 0.9284615516662598,\n",
       " 0.9307692050933838,\n",
       " 0.9292307496070862,\n",
       " 0.926153838634491,\n",
       " 0.9292307496070862,\n",
       " 0.9292307496070862,\n",
       " 0.9346153736114502,\n",
       " 0.936923086643219,\n",
       " 0.9376922845840454,\n",
       " 0.939230740070343,\n",
       " 0.939230740070343,\n",
       " 0.9399999976158142,\n",
       " 0.942307710647583,\n",
       " 0.9453846216201782,\n",
       " 0.9453846216201782,\n",
       " 0.947692334651947,\n",
       " 0.949999988079071,\n",
       " 0.9515384435653687,\n",
       " 0.947692334651947,\n",
       " 0.9576923251152039,\n",
       " 0.9584615230560303,\n",
       " 0.9592307806015015,\n",
       " 0.9676923155784607,\n",
       " 0.9653846025466919,\n",
       " 0.9684615135192871,\n",
       " 0.9700000286102295,\n",
       " 0.9700000286102295,\n",
       " 0.9553846120834351,\n",
       " 0.9684615135192871,\n",
       " 0.9707692265510559,\n",
       " 0.9730769395828247,\n",
       " 0.9738461375236511,\n",
       " 0.9738461375236511,\n",
       " 0.9784615635871887,\n",
       " 0.9700000286102295,\n",
       " 0.9738461375236511,\n",
       " 0.9723076820373535,\n",
       " 0.9746153950691223,\n",
       " 0.9784615635871887,\n",
       " 0.9761538505554199,\n",
       " 0.9746153950691223,\n",
       " 0.9761538505554199,\n",
       " 0.9738461375236511,\n",
       " 0.9769230484962463,\n",
       " 0.9792307615280151,\n",
       " 0.9761538505554199,\n",
       " 0.9746153950691223,\n",
       " 0.9738461375236511,\n",
       " 0.9738461375236511,\n",
       " 0.9769230484962463,\n",
       " 0.9769230484962463,\n",
       " 0.9761538505554199,\n",
       " 0.9776923060417175,\n",
       " 0.9753845930099487,\n",
       " 0.9769230484962463,\n",
       " 0.9776923060417175,\n",
       " 0.9753845930099487,\n",
       " 0.9738461375236511,\n",
       " 0.9776923060417175,\n",
       " 0.9784615635871887,\n",
       " 0.9746153950691223,\n",
       " 0.9784615635871887,\n",
       " 0.9792307615280151,\n",
       " 0.9776923060417175,\n",
       " 0.9753845930099487,\n",
       " 0.9784615635871887,\n",
       " 0.9792307615280151,\n",
       " 0.9776923060417175,\n",
       " 0.9807692170143127,\n",
       " 0.9807692170143127,\n",
       " 0.9784615635871887,\n",
       " 0.9753845930099487,\n",
       " 0.9784615635871887,\n",
       " 0.9792307615280151]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# x값을 지정하고 테스트셋 정확도를 파란색으로, 학습셋 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3, label='Trainset_accuracy')\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3, label='Testset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % y_val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epoch가 진행될수록 학습 셋 정확도는 1에 수렴하고, 테스트셋 오차는 점점 0에 수렴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
